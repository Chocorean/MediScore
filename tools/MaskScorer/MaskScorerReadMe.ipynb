{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "python2 MaskScorer.py -t task-type<br/>\n",
    "                      --refDir reference-directory<br/>\n",
    "                      -r reference-file<br/>\n",
    "                      -x index-file<br/>\n",
    "                      -s system-output-file<br/>\n",
    "                      --outRoot output-directory<br/>\n",
    "                      [options]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask scorer calculates performance scores that measure the accuracy of the system output masks to their corresponding reference masks. The script produces output files in the form of pipe-separated (\"|\") CSV files, one containing scores at the trial level (\\*-mask_scores-perimage.csv), another containing an average of the metrics in the first CSV (\\*-mask_score.csv), and a third containing a list of manipulations that were evaluated corresponding to the journal in each probe (\\*-journalResults.csv). If the -html option is selected, the script will generate a detailed HTML file for the mask region performance results.\n",
    "\n",
    "The mask scorer takes the following steps to score a mask:\n",
    "\n",
    "1. Reads in the reference and system masks.\n",
    "2. Binarizes the reference mask.\n",
    "3. Generates the no-score zone.\n",
    "4. Computes metrics \n",
    "\n",
    "If the script aborts due to an error, the error will be written to standard out, and the script will exit with a status of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Masks\n",
    "\n",
    "The system mask is read in as a single-layer grayscale png. (Note that the validator will fail the mask if it is not.) The reference mask is read in as a single-layer JPEG2000 containing bit values corresponding to localizable manipulations. If the evaluation is against color reference masks where mutually exclusive regions are RGB color-coded and different regions are easily distinguishable, the mask is read in as a three-channel (BGR-channel) png mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing the Reference Mask\n",
    "\n",
    "In order to score the system output mask against the reference mask, the reference mask also needs to be converted to a single-channel mask. The obvious way to do this would be to treat each of the regions with bit values (color regions for the color masks) as manipulated regions and to score accordingly.\n",
    "\n",
    "If selective scoring is utilized (via the -qm option), only regions that match the query will be scored against. The rest will be treated as no-score regions, to be discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating No-Score Zones\n",
    "\n",
    "No-score zones are generated by differencing the erosion and dilation of the ground truth positive pixels in the reference mask. The difference between the two is called the boundary no-score zone.\n",
    "\n",
    "If selective scoring is utilized (via the -qm option), the mask scorer also generates the distraction no-score zone by dilating the positive pixels of the irrelevant regions in the reference mask. This number need not be the same as the dilation parameter used to generate the boundary no-score zone.\n",
    "\n",
    "An additional system-generated no-score zone may be used by the performer. The performer specifies a particular pixel value to treat as a no-score zone. This no-score zone is joined with the aforementioned no-score zones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "The system computes the following metrics:\n",
    " * Matthews Correlation Coefficient (MCC)\n",
    " * Nimble Mask Metric (NMM)\n",
    " * Weighted L1 Loss: Binary (BWL1) and Grayscale (GWL1)\n",
    " * Area Under the ROC Curve (AUC)\n",
    "\n",
    "The set of metrics returned will be the ones with the largest MCC. These are called the \"optimum\" metrics. Additionally specifying a threshold for all images to be binarized via the --sbin option will yield the \"maximum\" and \"actual\" metrics: the maximum metrics are defined as the metric values that yield the largest average MCC for a fixed threshold across all images; the actual metrics are defined as the metric values at the binarization threshold chosen by the performer.\n",
    "\n",
    "Averages of the metrics will be recorded across all probes. The average and standard deviation of the optimum thresholds will also be recorded.\n",
    "\n",
    "### Notation\n",
    "\n",
    "The following notation is used in discussing the metrics:\n",
    " * $gt$ refers to the binarized reference mask\n",
    " * $sys_{\\theta}$ refers to the system output mask binarized by threshold $\\theta$\n",
    "   * $sys_{*}$ refers to the unbinarized grayscale system output mask\n",
    " * $wts$ is a matrix of 1's and 0's, which denote the pixels scored and exempt by the system respectively. It is generated by a difference in the erosion and dilation of the manipulated area of $gt$.\n",
    " * $TP$, $TN$, $FP$, and $FN$ are functions of $gt$, $sys_{\\theta}$, and $wts$. All four are measures derived from the confusion matrix. Pixels for which the weights matrix is equal to 0 are not counted in the confusion measures. These will also be reported in the perimage output file:\n",
    "   * $TP$ refers to the total number of True Positives, pixels where $gt$ is positive and $sys_{\\theta}$ is thresholded positive (manipulated)\n",
    "   * $TN$ refers to the total number of True Negatives, pixels where $gt$ is negative and $sys_{\\theta}$ is positive (not manipulated)\n",
    "   * $FP$ refers to the total number of False Positives, pixels where $gt$ is negative but $sys_{\\theta}$ is positive.\n",
    "   * $FN$ refers to the total number of False Negatives, pixels where $gt$ is positive but $sys_{\\theta}$ is negative.\n",
    "\n",
    "### Matthews Correlation Coefficient (MCC)\n",
    "\\begin{equation*}\n",
    "MCC(gt,sys_{\\theta}) = \\frac{TP*TN - FP*FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}\n",
    "\\end{equation*}\n",
    "\n",
    "An MCC of 1 denotes perfect correlation, an MCC of 0 denotes no correlation at all, and an MCC of -1 denotes perfect anti-correlation. If any of the sums in the denominator equals 0, the MCC is taken to be 0 by convention.\n",
    "\n",
    "### Nimble Mask Metric (NMM)\n",
    "\\begin{equation*}\n",
    "NMM(gt,sys_{\\theta},wts,c)=\\max{\\left(\\frac{TP - FN - FP}{\\sum\\limits_{px\\in gt}wts(px)},c\\right)}\n",
    "\\end{equation*}\n",
    "\n",
    "$\\Sigma_{px \\in GT}$ refers to the sum over the pixels in the ground truth that are marked black. $c$ denotes a minimum cutoff value for the scoring to have any meaning; by default, $c=-1$.\n",
    "\n",
    "### Weighted L1 Loss (BWL1 and GWL1)\n",
    "\n",
    "A Weighted L1 of 0 denotes perfect or near perfect match up to variation within the weights that are 0; 1 denotes perfect mismatch. $(FP+FN)_{weights > 0}$ refers to the total number of $FP$ and $FN$ pixels where weights are greater than 0.\n",
    "\n",
    "The Weighted L1 is applied separately to the original grayscale system output and the binarized mask, producing the grayscale Weighted L1 (GWL1) and binarized Weighted L1 (BWL1) metrics respectively. In the case of the original grayscale, the value is summed over the weighted difference in pixel intensity.\n",
    "\n",
    "\\begin{equation*}\n",
    "BWL1(gt,sys_{\\theta},wts)=\\frac{(FP+FN)_{wts > 0}}{\\sum\\limits_{px\\in gt}wts(px)}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "GWL1(gt,sys_{*},wts)=\\frac{\\sum\\limits_{px\\in gt} \\left|gt(px) - sys_{*}(px)\\right|wts(px)}{\\sum\\limits_{px\\in gt}wts(px)}\n",
    "\\end{equation*}\n",
    "\n",
    "### Area Under Curve (AUC)\n",
    "\n",
    "The possibility of multiple thresholds giving rise to a set of varying confusion measures gives rise to the receiver operating characteristic (ROC). The ROC curve measures a relation between the true positive rate ($TPR$) and false positive rate ($FPR$), defined as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "TPR = \\frac{TP}{TP + FN}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "FPR = \\frac{FP}{FP + TN}\n",
    "\\end{equation*}\n",
    "\n",
    "The area under the ROC curve (AUC) is a measure for the accuracy of the system.\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "AUC(gt,sys_{*},wts) = \\sum\\limits_{\\theta_{n} \\in \\{\\theta_{0},\\ldots,\\theta_{N-1}\\}} \\left(TPR(gt,sys_{\\theta_{n+1}},wts) + TPR(gt,sys_{\\theta_{n}},wts)\\right)\\left(FPR(gt,sys_{\\theta_{n+1}},wts) - FPR(gt,sys_{\\theta_{n}},wts)\\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves\n",
    "\n",
    "A pixel-weighted average ROC curve and probe-weighted average ROC curve will be recorded and defined across all thresholds relevant to all system masks. For a given threshold $\\theta$, the true positive rate (TPR) for the ROC curves are as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "TPR_{pixel}(\\theta) = \\frac{\\sum_{probes}TP_{\\theta}}{\\sum_{probes}\\left(TP_{\\theta} + FN_{\\theta}\\right)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "TPR_{probe}(\\theta) = \\frac{1}{|probes|}\\sum_{probes}\\frac{TP_{\\theta}}{TP_{\\theta} + FN_{\\theta}}\n",
    "\\end{equation*}\n",
    "\n",
    "The false postive rates (FPR) are defined similarly. The pixel weighted average and probe weighted average ROC curves are drawn from the pairs of (FPR,TPR) points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command-line options for the mask scorer can be categorized as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Type Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-t --task [manipulation, splice]\n",
    "\n",
    "  * Specify the task type for evaluation (default = manipulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Options\n",
    "\n",
    "All CSV files passed to the Mask Scorer must contain headers and must have their rows separated by pipe characters ('|'). Fields and values in the CSV should <i>not</i> be enclosed in quotes ( ' or \" ) if possible (e.g. entries 'foo', an empty field, and 'bar', in that order, should look like this in the csv: foo||bar). Additional specifications for the index and system output files can be found in the ValidatorNotebook.html file under the Validator directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--refDir\n",
    "\n",
    "  * Specify the reference and index data path (e.g. \"/NC2016_Test0601\") (default = .)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-r --inRef\n",
    "\n",
    "  * Specify the reference CSV file within refDir that contains the ground-truth information and metadata about each image. Key fields are TaskID, ProbeFileID, ProbeFileName, and ProbeMaskFileName, and if scoring on the 'splice' task, DonorFileID, DonorFileName, and DonorMaskFileName as well. Often the File ID's for the Probe and Donor will be the same as the file names, minus the extension. Additional fields, especially metadata pertaining to the ground-truth manipulation, may be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-x --inIndex\n",
    "\n",
    "  * Define the index CSV file within refDir. The index file contains the TaskID, ProbeFileID, ProbeFileName, ProbeWidth, and ProbeHeight fields, and if scoring on the splice task, the DonorFileID, DonorFileName, DonorWidth, and DonorHeight fields as well. No additional fields are permitted for the index file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--sysDir\n",
    "\n",
    "  * Specify the system output data path, for example \"mysysoutput/\" (default = .) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-s --inSys\n",
    "\n",
    "  * Specify the CSV file of the system performance results formatted according to NC2016 specification. The file must contain the ProbeFileID, ConfidenceScore, and ProbeOutputMaskFileName fields, in that order, and if scoring on the splice task, the ProbeFileID, DonorFileID, ConfidenceScore, ProbeOutputMaskFileName, and DonorOutputMaskFileName fields, in that order. The ProbeOutputMaskFileNames and DonorOutputMaskFileNames (where relevant) should be directory strings relative to the location of the system performance CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--sbin\n",
    "\n",
    "  * Evaluate the system output masks as binarized masks with a numeric threshold in the interval [0,255]. Choosing -1 will forego this option. (default = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--color\n",
    "\n",
    "  * Evaluate the system output against colorized referenced masks. Individual regions in the colorized masks are identifiable by region and do not intersect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--outRoot\n",
    "\n",
    "  * Specify the report output path. The file name will take from the name of the For example, if you specify \"--outRoot test\" for a submission NIST_001, you will find the aggregate score report \"NIST_001-mask_score.csv\" and the per-image report \"NIST_001-mask_scores_perimage.csv\" in the \"test\" folder.\n",
    "\n",
    "--outMeta\n",
    "  * Save the CSV file with the system output with minimal metadata. This is a separate file than the normal outputs.\n",
    "\n",
    "--outAllMeta\n",
    "  * Save the CSV file with the system output with all available metadata. This is a separate file than the normal outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--eks\n",
    "\n",
    "  * Erosion kernel size. (number must be odd; default = 15)\n",
    "  \n",
    "--dks\n",
    "\n",
    "  * Dilation kernel size. (number must be odd; default = 11)\n",
    "\n",
    "--ntdks\n",
    "\n",
    "  * Non-target dilation kernel for regions that the user does not want scored. (number must be odd; default = 15)\n",
    "\n",
    "--nspx\n",
    "\n",
    "  * Set a pixel value in the system output mask to be a no-score region. The pixel value must be in the interval [0,255]. -1 indicates that no particular pixel value will be chosen to be the no-score zone. (default = -1)\n",
    "\n",
    "-k kernel\n",
    "\n",
    "  * The shape of the kernel to be used, for both erosion and dilation. Choose from 'box','disc','diamond','gaussian', or 'line'. The default kernel is 'box'.\n",
    "  \n",
    "-xF indexFilter\n",
    "\n",
    "  * Filter scoring to only files that are present in the index file. This option permits scoring to select index files for the purpose of testing, and may accept system outputs that have not passed the validator.\n",
    "\n",
    "--speedup\n",
    "\n",
    "  * Run mask evaluation with a sped-up evaluator.\n",
    "  \n",
    "-p processors\n",
    "\n",
    "  * Run mask evaluation with multiple processors to speed up computation further. (default = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation by Query\n",
    "\n",
    "This option allows the user to evaluate their algorithm performance on either subsets or partitions of the data based on the specified queries and query options. The reference and index CSV files contain a list of factors (e.g., ProbePostProcessed|DonorPostProcessed|ManipulationQuality|IsManipulationTypeRemoval|...). Selecting none of the following factors will output a single report table (CSV) over the entire computed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-q query\n",
    " * Evaluate algorithm performance on a partitioned dataset using multiple factor queries, one at a time (e.g. \"Collection==['NC2017'] & Purpose==['add','remove']\" will average over the rows that fit this criterion for one queried average, but \"Collection==['NC2017']\" \"Purpose==['add','remove']\" will average over the first and then the second independently for two queried averages). The option generates N report tables (CSV), one for each query.\n",
    "   * Syntax: -q \"query1\" \"query2\" \"query3\" ...\n",
    "   - The syntax is the same as Pandas' query syntax. Please see the detailed query rule in the website: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-query.\n",
    "   \n",
    "   Examples:\n",
    "   \n",
    "   % -q \"Collection==['Nimble-SCI']\" => 1 query\n",
    "   \n",
    "   % -q \"Collection==['Nimble-SCI'] and PostProcessing=['rescale']\" => 1 query\n",
    "   \n",
    "   % -q \"Collection==['Nimble-SCI','Nimble-WEB']\" \"PostProcessing=['rescale']\" \"200<ProbeWidth<=3000\" => 3 queries\n",
    "\n",
    "-qp queryPartition\n",
    " * Uses one factor query to evaluate algorithm performance on a partitioned dataset through its individual sub-queries (e.g. \"Collection==['NC2017'] & Purpose==['add','remove']\" will average over \"Collection==['NC2017'] & Purpose==['add']\" and \"Collection==['NC2017'] & Purpose==['remove']\" for a total of two queried averages). This option generates a single report table (CSV) that contains M partition results, one result for each query.\n",
    "   * Syntax: -qp \"query\"\n",
    "   \n",
    "   Examples:\n",
    "   \n",
    "   % -qp \"Collection==['Nimble-SCI']\" => 1 partition\n",
    "   \n",
    "   % -qp \"Collection==['Nimble-SCI','Nimble-WEB'] & PostProcessing=['rescale']\" => 2 partitions\n",
    "   \n",
    "   % -qp \"Collection==['Nimble-SCI','Nimble-WEB'] & PostProcessing=['rescale','noise']\" => 4 partitions\n",
    "   \n",
    "-qm queryManipulation\n",
    " * Filters the dataset before scoring takes place for some number of queries. It is functionally similar to the -q query option. The option generates M report tables (CSV), one for each query.\n",
    "   * Syntax: -qm \"query1\" \"query2\" \"query3\" ...\n",
    "   - Like the -q option, the syntax is the same as Pandas' query syntax.\n",
    "   \n",
    "   Examples:\n",
    "   \n",
    "   % -qm \"Purpose==['remove']\" => 1 query\n",
    "   \n",
    "   % -qm \"Operation==['PasteSplice']\" \"Operation==['FillContentAwareFill']\" => 2 query\n",
    "   \n",
    "   % -qm \"Purpose==['remove']\" \"Purpose==['add']\" \"Purpose==['splice']\"=> 3 queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-v verbose\n",
    "\n",
    "  * Control print output. Select 1 to print all non-error related output and 0 to suppress all print output (bar argument-parsing errors).\n",
    "  \n",
    "--precision\n",
    "\n",
    "  * The number of digits to round computed scores, (e.g. a score of 0.3333333333333... will round to 0.33333 for a precision of 5), (default = 16).\n",
    "\n",
    "-html\n",
    "\n",
    "  * Output the report to HTML files to visualize scoring.\n",
    "  \n",
    "--optOut\n",
    "\n",
    "  * Evaluate algorithm performance on trials where the IsOptOut value is not 'Y'.\n",
    "  \n",
    "--displayScoredOnly\n",
    "\n",
    "  * Display only the data for which a localized score could be generated. This will exclude images for which there are no score-able regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current query: ConfidenceScore < 0.5\n",
      "Current query: ManMade==['no']\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python MaskScorer.py -t manipulation --refDir ../../data/test_suite/maskScorerTests \\\n",
    "-r reference/manipulation/NC2017-manipulation-ref.csv -x indexes/NC2017-manipulation-index.csv \\\n",
    "-s ../../data/test_suite/maskScorerTests/B_NC2017_Manipulation_ImgOnly_c-me2_1/B_NC2017_Manipulation_ImgOnly_c-me2_1.csv \\\n",
    "-oR outputs/maniptest -html -q \"ConfidenceScore < 0.5\" \"ManMade==['no']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this code in the tools/MaskScorer directory will generate an aggregate report of the computed mask scores titled B_NC2017_Manipulation_ImgOnly_c-me2_1-mask_scores.csv and a per-image score report titled B_NC2017_Manipulation_ImgOnly_c-me2_1-mask_scores_perimage.csv for the manipulation task.\n",
    "\n",
    "The -html flag is also set, allowing the code to generate an HTML per-image <a href=\"outputs/maniptest/index.html\">index file</a> with the scores and metadata containing links to individual detailed reports of each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user may also select which manipulation regions to score, depending on the manipulations listed under the \"Purpose\" column in the journalMask file. Other regions are dilated by a separate factor and counted as selective no-score zones in addition to the boundary no-score zones applied to the regions of interest. Multiple pre-filters can be applied independently to the data, resulting in the output of multiple output indices corresponding to the number of queries passed to -qm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python MaskScorer.py -t manipulation --refDir ../../data/test_suite/maskScorerTests \\\n",
    "-r reference/manipulation/NC2017-manipulation-ref.csv -x indexes/NC2017-manipulation-index.csv \\\n",
    "-s ../../data/test_suite/maskScorerTests/B_NC2017_Manipulation_ImgOnly_c-me2_1/B_NC2017_Manipulation_ImgOnly_c-me2_1.csv \\\n",
    "-oR outputs/maniptargets -html -qm \"Purpose==['remove']\" \"Purpose==['clone','add']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample HTML index files for the 'remove' and 'clone','add' operations can be found <a href=\"outputs/maniptargets/index_0/index.html\">here</a> and <a href=\"outputs/maniptargets/index_1/index.html\">here</a> respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Disclaimer\n",
    "\n",
    "This software was developed at the National Institute of Standards\n",
    "and Technology (NIST) by employees of the Federal Government in the\n",
    "course of their official duties. Pursuant to Title 17 Section 105\n",
    "of the United States Code, this software is not subject to copyright\n",
    "protection and is in the public domain. NIST assumes no responsibility\n",
    "whatsoever for use by other parties of its source code or open source\n",
    "server, and makes no guarantees, expressed or implied, about its quality,\n",
    "reliability, or any other characteristic."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ipykernel_py2]",
   "language": "python",
   "name": "conda-env-ipykernel_py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
